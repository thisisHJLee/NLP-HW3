{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "71/71 [==============================] - 12s 171ms/step - loss: 2.6297 - acc: 0.3398 - val_loss: 2.3875 - val_acc: 0.3620\n",
      "Epoch 2/20\n",
      "71/71 [==============================] - 11s 154ms/step - loss: 2.2986 - acc: 0.4325 - val_loss: 2.3019 - val_acc: 0.4711\n",
      "Epoch 3/20\n",
      "71/71 [==============================] - 11s 152ms/step - loss: 2.0798 - acc: 0.5000 - val_loss: 1.9676 - val_acc: 0.5120\n",
      "Epoch 4/20\n",
      "71/71 [==============================] - 12s 174ms/step - loss: 1.8708 - acc: 0.5174 - val_loss: 1.8047 - val_acc: 0.5370\n",
      "Epoch 5/20\n",
      "71/71 [==============================] - 12s 167ms/step - loss: 1.7564 - acc: 0.5475 - val_loss: 1.7536 - val_acc: 0.5463\n",
      "Epoch 6/20\n",
      "71/71 [==============================] - 11s 150ms/step - loss: 1.6778 - acc: 0.5574 - val_loss: 1.7275 - val_acc: 0.5592\n",
      "Epoch 7/20\n",
      "71/71 [==============================] - 10s 148ms/step - loss: 1.6227 - acc: 0.5843 - val_loss: 1.7138 - val_acc: 0.5748\n",
      "Epoch 8/20\n",
      "71/71 [==============================] - 11s 160ms/step - loss: 1.5232 - acc: 0.6145 - val_loss: 1.6110 - val_acc: 0.5926\n",
      "Epoch 9/20\n",
      "71/71 [==============================] - 11s 152ms/step - loss: 1.4494 - acc: 0.6325 - val_loss: 1.5256 - val_acc: 0.6251\n",
      "Epoch 10/20\n",
      "71/71 [==============================] - 11s 152ms/step - loss: 1.3384 - acc: 0.6589 - val_loss: 1.4401 - val_acc: 0.6362\n",
      "Epoch 11/20\n",
      "71/71 [==============================] - 11s 149ms/step - loss: 1.2603 - acc: 0.6775 - val_loss: 1.3746 - val_acc: 0.6572\n",
      "Epoch 12/20\n",
      "71/71 [==============================] - 11s 151ms/step - loss: 1.2688 - acc: 0.6725 - val_loss: 1.4166 - val_acc: 0.6447\n",
      "Epoch 13/20\n",
      "71/71 [==============================] - 11s 151ms/step - loss: 1.1702 - acc: 0.7030 - val_loss: 1.3828 - val_acc: 0.6598\n",
      "Epoch 14/20\n",
      "71/71 [==============================] - 11s 152ms/step - loss: 1.1544 - acc: 0.7031 - val_loss: 1.3323 - val_acc: 0.6492\n",
      "Epoch 15/20\n",
      "71/71 [==============================] - 11s 151ms/step - loss: 1.0826 - acc: 0.7196 - val_loss: 1.3123 - val_acc: 0.6674\n",
      "Epoch 16/20\n",
      "71/71 [==============================] - 11s 158ms/step - loss: 1.0389 - acc: 0.7339 - val_loss: 1.2771 - val_acc: 0.6790\n",
      "Epoch 17/20\n",
      "71/71 [==============================] - 11s 153ms/step - loss: 0.9851 - acc: 0.7458 - val_loss: 1.2669 - val_acc: 0.6736\n",
      "Epoch 18/20\n",
      "71/71 [==============================] - 11s 154ms/step - loss: 0.9647 - acc: 0.7513 - val_loss: 1.2932 - val_acc: 0.6834\n",
      "Epoch 19/20\n",
      "71/71 [==============================] - 12s 169ms/step - loss: 0.9391 - acc: 0.7583 - val_loss: 1.2473 - val_acc: 0.6972\n",
      "Epoch 20/20\n",
      "71/71 [==============================] - 12s 164ms/step - loss: 0.8884 - acc: 0.7731 - val_loss: 1.2267 - val_acc: 0.6937\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=1000, test_split=0.2)\n",
    "\n",
    "max_len = 100\n",
    "X_train = pad_sequences(X_train, maxlen=max_len) # 훈련용 뉴스 기사 패딩\n",
    "X_test = pad_sequences(X_test, maxlen=max_len) # 테스트용 뉴스 기사 패딩\n",
    "\n",
    "y_train = to_categorical(y_train) # 훈련용 뉴스 기사 레이블의 원-핫 인코딩\n",
    "y_test = to_categorical(y_test) # 테스트용 뉴스 기사 레이블의 원-핫 인코딩\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(1000, 120))\n",
    "model.add(LSTM(120))\n",
    "model.add(Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=128, epochs=20, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 뉴스 기사 : 8982\n",
      "테스트용 뉴스 기사 : 2246\n",
      "카테고리 : 46\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
    "\n",
    "print('훈련용 뉴스 기사 : {}'.format(len(X_train)))\n",
    "print('테스트용 뉴스 기사 : {}'.format(len(X_test)))\n",
    "num_classes = max(y_train) + 1\n",
    "print('카테고리 : {}'.format(num_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Temp\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axe = plt.subplots(ncols=1)\n",
    "fig.set_size_inches(12,5)\n",
    "sns.countplot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 16, 19, 8, 21, 11, 1, 13, 20, 18, 25, 35, 9, 38, 10, 28, 2, 6, 12, 7, 30, 34, 15, 14, 32, 41, 40, 45, 23, 42, 26, 24, 37, 27, 31, 39, 0, 22, 33, 36, 17, 43, 29, 44, 5]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n"
     ]
    }
   ],
   "source": [
    "new_list = []\n",
    "for i in y_train:\n",
    "    if i not in new_list:\n",
    "        new_list.append(i)\n",
    "\n",
    "print(new_list)\n",
    "\n",
    "new_list.sort()\n",
    "print(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터  0  : 카테고리  3\n",
      "데이터  1  : 카테고리  4\n",
      "데이터  2  : 카테고리  3\n",
      "데이터  3  : 카테고리  4\n",
      "데이터  4  : 카테고리  4\n",
      "데이터  5  : 카테고리  4\n",
      "데이터  6  : 카테고리  4\n",
      "데이터  7  : 카테고리  3\n",
      "데이터  8  : 카테고리  3\n",
      "데이터  9  : 카테고리  16\n",
      "데이터  10  : 카테고리  3\n",
      "데이터  11  : 카테고리  3\n",
      "데이터  12  : 카테고리  4\n",
      "데이터  13  : 카테고리  4\n",
      "데이터  14  : 카테고리  19\n",
      "데이터  15  : 카테고리  8\n",
      "데이터  16  : 카테고리  16\n",
      "데이터  17  : 카테고리  3\n",
      "데이터  18  : 카테고리  3\n",
      "데이터  19  : 카테고리  21\n",
      "데이터  20  : 카테고리  11\n",
      "데이터  21  : 카테고리  4\n",
      "데이터  22  : 카테고리  4\n",
      "데이터  23  : 카테고리  3\n",
      "데이터  24  : 카테고리  3\n",
      "데이터  25  : 카테고리  1\n",
      "데이터  26  : 카테고리  3\n",
      "데이터  27  : 카테고리  1\n",
      "데이터  28  : 카테고리  3\n",
      "데이터  29  : 카테고리  16\n",
      "데이터  30  : 카테고리  1\n",
      "데이터  31  : 카테고리  4\n",
      "데이터  32  : 카테고리  13\n",
      "데이터  33  : 카테고리  20\n",
      "데이터  34  : 카테고리  1\n",
      "데이터  35  : 카테고리  4\n",
      "데이터  36  : 카테고리  4\n",
      "데이터  37  : 카테고리  11\n",
      "데이터  38  : 카테고리  3\n",
      "데이터  39  : 카테고리  3\n",
      "데이터  40  : 카테고리  3\n",
      "데이터  41  : 카테고리  11\n",
      "데이터  42  : 카테고리  16\n",
      "데이터  43  : 카테고리  4\n",
      "데이터  44  : 카테고리  4\n",
      "데이터  45  : 카테고리  20\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, num_classes):\n",
    "    print('데이터 ', i, ' : 카테고리 ', y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n",
      "데이터  1  : 카테고리  4\n",
      "데이터  2  : 카테고리  3\n",
      "데이터  3  : 카테고리  4\n",
      "데이터  4  : 카테고리  4\n",
      "데이터  5  : 카테고리  4\n",
      "데이터  6  : 카테고리  4\n",
      "데이터  7  : 카테고리  3\n",
      "데이터  8  : 카테고리  3\n",
      "데이터  9  : 카테고리  16\n",
      "데이터  10  : 카테고리  3\n",
      "데이터  11  : 카테고리  3\n",
      "데이터  12  : 카테고리  4\n",
      "데이터  13  : 카테고리  4\n",
      "데이터  14  : 카테고리  19\n",
      "데이터  15  : 카테고리  8\n",
      "데이터  16  : 카테고리  16\n",
      "데이터  17  : 카테고리  3\n",
      "데이터  18  : 카테고리  3\n",
      "데이터  19  : 카테고리  21\n",
      "데이터  20  : 카테고리  11\n",
      "데이터  21  : 카테고리  4\n",
      "데이터  22  : 카테고리  4\n",
      "데이터  23  : 카테고리  3\n",
      "데이터  24  : 카테고리  3\n",
      "데이터  25  : 카테고리  1\n",
      "데이터  26  : 카테고리  3\n",
      "데이터  27  : 카테고리  1\n",
      "데이터  28  : 카테고리  3\n",
      "데이터  29  : 카테고리  16\n",
      "데이터  30  : 카테고리  1\n",
      "데이터  31  : 카테고리  4\n",
      "데이터  32  : 카테고리  13\n",
      "데이터  33  : 카테고리  20\n",
      "데이터  34  : 카테고리  1\n",
      "데이터  35  : 카테고리  4\n",
      "데이터  36  : 카테고리  4\n",
      "데이터  37  : 카테고리  11\n",
      "데이터  38  : 카테고리  3\n",
      "데이터  39  : 카테고리  3\n",
      "데이터  40  : 카테고리  3\n",
      "데이터  41  : 카테고리  11\n",
      "데이터  42  : 카테고리  16\n",
      "데이터  43  : 카테고리  4\n",
      "데이터  44  : 카테고리  4\n",
      "데이터  45  : 카테고리  20\n",
      "데이터  46  : 카테고리  18\n",
      "데이터  47  : 카테고리  25\n",
      "데이터  48  : 카테고리  19\n",
      "데이터  49  : 카테고리  3\n",
      "데이터  50  : 카테고리  4\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
    "\n",
    "new_list = []\n",
    "for i in y_train:\n",
    "    if i not in new_list:\n",
    "        new_list.append(i)\n",
    "\n",
    "# print(new_list)\n",
    "new_list.sort()\n",
    "print(new_list)\n",
    "\n",
    "for i in range(1, 51):\n",
    "    print('데이터 ', i, ' : 카테고리 ', y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45]\n",
      "데이터  1  : 카테고리  10\n",
      "데이터  2  : 카테고리  1\n",
      "데이터  3  : 카테고리  4\n",
      "데이터  4  : 카테고리  4\n",
      "데이터  5  : 카테고리  3\n",
      "데이터  6  : 카테고리  3\n",
      "데이터  7  : 카테고리  3\n",
      "데이터  8  : 카테고리  3\n",
      "데이터  9  : 카테고리  3\n",
      "데이터  10  : 카테고리  5\n",
      "데이터  11  : 카테고리  4\n",
      "데이터  12  : 카테고리  1\n",
      "데이터  13  : 카테고리  3\n",
      "데이터  14  : 카테고리  1\n",
      "데이터  15  : 카테고리  11\n",
      "데이터  16  : 카테고리  23\n",
      "데이터  17  : 카테고리  3\n",
      "데이터  18  : 카테고리  19\n",
      "데이터  19  : 카테고리  3\n",
      "데이터  20  : 카테고리  8\n",
      "데이터  21  : 카테고리  3\n",
      "데이터  22  : 카테고리  3\n",
      "데이터  23  : 카테고리  3\n",
      "데이터  24  : 카테고리  9\n",
      "데이터  25  : 카테고리  3\n",
      "데이터  26  : 카테고리  4\n",
      "데이터  27  : 카테고리  6\n",
      "데이터  28  : 카테고리  10\n",
      "데이터  29  : 카테고리  3\n",
      "데이터  30  : 카테고리  3\n",
      "데이터  31  : 카테고리  10\n",
      "데이터  32  : 카테고리  20\n",
      "데이터  33  : 카테고리  1\n",
      "데이터  34  : 카테고리  19\n",
      "데이터  35  : 카테고리  4\n",
      "데이터  36  : 카테고리  40\n",
      "데이터  37  : 카테고리  1\n",
      "데이터  38  : 카테고리  4\n",
      "데이터  39  : 카테고리  3\n",
      "데이터  40  : 카테고리  15\n",
      "데이터  41  : 카테고리  21\n",
      "데이터  42  : 카테고리  3\n",
      "데이터  43  : 카테고리  34\n",
      "데이터  44  : 카테고리  4\n",
      "데이터  45  : 카테고리  4\n",
      "데이터  46  : 카테고리  3\n",
      "데이터  47  : 카테고리  4\n",
      "데이터  48  : 카테고리  3\n",
      "데이터  49  : 카테고리  11\n",
      "데이터  50  : 카테고리  20\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)\n",
    "\n",
    "new_list = []\n",
    "for i in y_test:\n",
    "    if i not in new_list:\n",
    "        new_list.append(i)\n",
    "\n",
    "# print(new_list)\n",
    "new_list.sort()\n",
    "print(new_list)\n",
    "\n",
    "for i in range(1, 51):\n",
    "    print('데이터 ', i, ' : 카테고리 ', y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.4579 - accuracy: 0.8178\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 1s 16ms/step - loss: 0.2623 - accuracy: 0.9084\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.2017 - accuracy: 0.9272\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 1s 13ms/step - loss: 0.1674 - accuracy: 0.9402\n",
      "782/782 [==============================] - 1s 2ms/step - loss: 0.2960 - accuracy: 0.8816\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = \timdb.load_data( num_words=10000)\n",
    "\n",
    "import numpy as np\n",
    "# 입력 텍스트 vectorization\n",
    "def vectorize_sequences(sequences, dimension=10000): \n",
    "\tresults = np.zeros((len(sequences), dimension)) \n",
    "\tfor i, sequence in enumerate(sequences): \n",
    "\t\tresults[i, sequence] = 1. \n",
    "\treturn results \n",
    "\n",
    "x_train = vectorize_sequences(train_data) \n",
    "x_test = vectorize_sequences(test_data)\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "from keras import models \n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential() \n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,))) \n",
    "model.add(layers.Dense(16, activation='relu')) \n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', \n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 17ms/step - loss: 0.4551 - accuracy: 0.8292\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 1s 15ms/step - loss: 0.2800 - accuracy: 0.9076\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.2214 - accuracy: 0.9245\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 1s 14ms/step - loss: 0.1887 - accuracy: 0.9361\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.2817 - accuracy: 0.8870\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = \timdb.load_data( num_words=10000)\n",
    "\n",
    "import numpy as np\n",
    "# 입력 텍스트 vectorization\n",
    "def vectorize_sequences(sequences, dimension=10000): \n",
    "\tresults = np.zeros((len(sequences), dimension)) \n",
    "\tfor i, sequence in enumerate(sequences): \n",
    "\t\tresults[i, sequence] = 1. \n",
    "\treturn results \n",
    "\n",
    "x_train = vectorize_sequences(train_data) \n",
    "x_test = vectorize_sequences(test_data)\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "from keras import models \n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential() \n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,))) \n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', \n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 22ms/step - loss: 0.4251 - accuracy: 0.8263\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 1s 21ms/step - loss: 0.2498 - accuracy: 0.9124\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 1s 18ms/step - loss: 0.2007 - accuracy: 0.9303\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 1s 17ms/step - loss: 0.1701 - accuracy: 0.9404\n",
      "782/782 [==============================] - 2s 2ms/step - loss: 0.3142 - accuracy: 0.8738\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = \timdb.load_data( num_words=10000)\n",
    "\n",
    "import numpy as np\n",
    "# 입력 텍스트 vectorization\n",
    "def vectorize_sequences(sequences, dimension=10000): \n",
    "\tresults = np.zeros((len(sequences), dimension)) \n",
    "\tfor i, sequence in enumerate(sequences): \n",
    "\t\tresults[i, sequence] = 1. \n",
    "\treturn results \n",
    "\n",
    "x_train = vectorize_sequences(train_data) \n",
    "x_test = vectorize_sequences(test_data)\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "from keras import models \n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential() \n",
    "model.add(layers.Dense(32, activation='relu', input_shape=(10000,))) \n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', \n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.4098 - accuracy: 0.8189\n",
      "Epoch 2/4\n",
      "49/49 [==============================] - 1s 27ms/step - loss: 0.2419 - accuracy: 0.9125\n",
      "Epoch 3/4\n",
      "49/49 [==============================] - 1s 26ms/step - loss: 0.1905 - accuracy: 0.9303\n",
      "Epoch 4/4\n",
      "49/49 [==============================] - 1s 25ms/step - loss: 0.1613 - accuracy: 0.9422\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.3322 - accuracy: 0.8691\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "(train_data, train_labels), (test_data, test_labels) = \timdb.load_data( num_words=10000)\n",
    "\n",
    "import numpy as np\n",
    "# 입력 텍스트 vectorization\n",
    "def vectorize_sequences(sequences, dimension=10000): \n",
    "\tresults = np.zeros((len(sequences), dimension)) \n",
    "\tfor i, sequence in enumerate(sequences): \n",
    "\t\tresults[i, sequence] = 1. \n",
    "\treturn results \n",
    "\n",
    "x_train = vectorize_sequences(train_data) \n",
    "x_test = vectorize_sequences(test_data)\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "from keras import models \n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential() \n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,))) \n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', \n",
    "\tmetrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=4, batch_size=512)\n",
    "results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 2.9523 - accuracy: 0.4757 - val_loss: 2.0626 - val_accuracy: 0.6520\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 1.6313 - accuracy: 0.6937 - val_loss: 1.4092 - val_accuracy: 0.6960\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 1.1372 - accuracy: 0.7632 - val_loss: 1.1845 - val_accuracy: 0.7560\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 1s 33ms/step - loss: 0.8900 - accuracy: 0.8128 - val_loss: 1.0578 - val_accuracy: 0.7810\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.7163 - accuracy: 0.8559 - val_loss: 0.9937 - val_accuracy: 0.7920\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.5834 - accuracy: 0.8831 - val_loss: 0.9602 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.4761 - accuracy: 0.9047 - val_loss: 0.9171 - val_accuracy: 0.8150\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.3895 - accuracy: 0.9191 - val_loss: 0.9420 - val_accuracy: 0.8060\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.3260 - accuracy: 0.9301 - val_loss: 0.9104 - val_accuracy: 0.8120\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.2732 - accuracy: 0.9411 - val_loss: 0.9046 - val_accuracy: 0.8150\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 1s 32ms/step - loss: 0.2343 - accuracy: 0.9479 - val_loss: 0.9248 - val_accuracy: 0.8180\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.2073 - accuracy: 0.9491 - val_loss: 0.9407 - val_accuracy: 0.8190\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1786 - accuracy: 0.9513 - val_loss: 1.0028 - val_accuracy: 0.7950\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1712 - accuracy: 0.9533 - val_loss: 0.9617 - val_accuracy: 0.8170\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1536 - accuracy: 0.9540 - val_loss: 0.9718 - val_accuracy: 0.8150\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1450 - accuracy: 0.9538 - val_loss: 0.9943 - val_accuracy: 0.8200\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1342 - accuracy: 0.9554 - val_loss: 1.0147 - val_accuracy: 0.8200\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.1295 - accuracy: 0.9572 - val_loss: 1.0604 - val_accuracy: 0.8030\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.1234 - accuracy: 0.9575 - val_loss: 1.0143 - val_accuracy: 0.8150\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1187 - accuracy: 0.9589 - val_loss: 1.0915 - val_accuracy: 0.8010\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "x_train = vectorize_sequences(train_data) # 훈련 데이터 벡터 변환\n",
    "x_test = vectorize_sequences(test_data) # 테스트 데이터 벡터 변환\n",
    "\n",
    "one_hot_train_labels = to_categorical(train_labels)\n",
    "one_hot_test_labels = to_categorical(test_labels)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "x_val = x_train[:1000]\n",
    "partial_x_train = x_train[1000:]\n",
    "\n",
    "y_val = one_hot_train_labels[:1000]\n",
    "partial_y_train = one_hot_train_labels[1000:]\n",
    "\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 2.5602 - accuracy: 0.5200 - val_loss: 1.6963 - val_accuracy: 0.6380\n",
      "Epoch 2/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 1.3977 - accuracy: 0.7043 - val_loss: 1.3296 - val_accuracy: 0.7110\n",
      "Epoch 3/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 1.0654 - accuracy: 0.7700 - val_loss: 1.1518 - val_accuracy: 0.7560\n",
      "Epoch 4/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.8476 - accuracy: 0.8161 - val_loss: 1.0618 - val_accuracy: 0.7730\n",
      "Epoch 5/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.6713 - accuracy: 0.8579 - val_loss: 0.9932 - val_accuracy: 0.7800\n",
      "Epoch 6/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.5380 - accuracy: 0.8867 - val_loss: 0.9275 - val_accuracy: 0.8090\n",
      "Epoch 7/20\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.4300 - accuracy: 0.9129 - val_loss: 0.9021 - val_accuracy: 0.8120\n",
      "Epoch 8/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.3515 - accuracy: 0.9268 - val_loss: 0.9061 - val_accuracy: 0.8060\n",
      "Epoch 9/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.2854 - accuracy: 0.9369 - val_loss: 0.9030 - val_accuracy: 0.8120\n",
      "Epoch 10/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.2446 - accuracy: 0.9430 - val_loss: 0.8879 - val_accuracy: 0.8230\n",
      "Epoch 11/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.2120 - accuracy: 0.9478 - val_loss: 0.9102 - val_accuracy: 0.8030\n",
      "Epoch 12/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1858 - accuracy: 0.9520 - val_loss: 0.9102 - val_accuracy: 0.8100\n",
      "Epoch 13/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1625 - accuracy: 0.9531 - val_loss: 1.0337 - val_accuracy: 0.7860\n",
      "Epoch 14/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1509 - accuracy: 0.9554 - val_loss: 1.0368 - val_accuracy: 0.7980\n",
      "Epoch 15/20\n",
      "16/16 [==============================] - 0s 25ms/step - loss: 0.1380 - accuracy: 0.9570 - val_loss: 0.9473 - val_accuracy: 0.8160\n",
      "Epoch 16/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1333 - accuracy: 0.9546 - val_loss: 0.9982 - val_accuracy: 0.8040\n",
      "Epoch 17/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1238 - accuracy: 0.9535 - val_loss: 1.0358 - val_accuracy: 0.7970\n",
      "Epoch 18/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1193 - accuracy: 0.9568 - val_loss: 1.0331 - val_accuracy: 0.8020\n",
      "Epoch 19/20\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.1154 - accuracy: 0.9577 - val_loss: 1.0727 - val_accuracy: 0.8020\n",
      "Epoch 20/20\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.1104 - accuracy: 0.9573 - val_loss: 1.0541 - val_accuracy: 0.8040\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import reuters\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words=10000)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def vectorize_sequences(sequences, dimension=10000):\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, sequence in enumerate(sequences):\n",
    "        results[i, sequence] = 1.\n",
    "    return results\n",
    "\n",
    "X_train = vectorize_sequences(train_data) # 훈련 데이터 벡터 변환\n",
    "X_test = vectorize_sequences(test_data) # 테스트 데이터 벡터 변환\n",
    "\n",
    "y_train = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(46, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "x_val = X_train[:1000]\n",
    "partial_x_train = X_train[1000:]\n",
    "\n",
    "y_val = y_train[:1000]\n",
    "partial_y_train = y_train[1000:]\n",
    "\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
